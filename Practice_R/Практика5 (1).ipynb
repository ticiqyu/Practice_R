{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # библиотека для эффективной работы с данными \nimport pandas as pd # библиотека для работы с наборами данных \nimport matplotlib.pyplot as plt # библиотека для визуализации\nimport seaborn as sns # еще одна библиотека для построения графиков ","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('creditcard.csv')\ndata.shape","metadata":{"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(284807, 31)"},"metadata":{}}]},{"cell_type":"code","source":"data.info() # выводим информацию о наборе данных ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe() # статистический анализ числовых столбцов \ndata.corr() # корреляция числовых столбцов","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.heatmap(data.corr(), xticklabels=data.corr().columns, yticklabels=data.corr().columns, cmap='RdYlGn', center=0, annot=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Нормализация факторных переменных\nfrom sklearn.preprocessing import StandardScaler \nscale_features_std = StandardScaler()\nfeatures_std = scale_features_std.fit_transform(data[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7','V8', 'V9', 'V10', 'V11',\n'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18','V19', 'V20', 'V21', 'V21',\n'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']])\nfeatures_std\ndata[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7','V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n'V19', 'V20', 'V21', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']]= features_std\ndata.head() \ndata.describe() #Целевой признак \ntarget=data.Class \ntrain=data\n\n#Выделяем тренировочную и тестовую выборки\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.3, random_state = 42)\nN_train, _ = X_train.shape\nN_test, _ = X_test.shape \nprint (N_train, N_test)\n#Метод главных компонентов\nfrom sklearn.decomposition import PCA\n%matplotlib inline\nimport matplotlib.pyplot as plt\npca = PCA() \npca.fit(X_train)\nX_pca = pca.transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, component in enumerate(pca.components_):print(\"{} component: {}% of initial variance\".format(i + 1, round(100 * pca.explained_variance_ratio_[i], 2)))\nprint(\" + \".join(\"%.3f x %s\" % (value, name)for value, name in zip(component,train.columns)))\nplt.figure(figsize=(10,5)) \nplt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2) \nplt.axhline(0.9, c='r')\nplt.axvline(10, c='b')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"less_dimensional_X = pca.transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, random_state=0)\ntsne_results = tsne.fit_transform(less_dimensional_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne_df = pd.DataFrame({'X':tsne_results[:,0],\n                        'Y':tsne_results[:,1],\n                        'real_ans':y_train})\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(7, 7))\nsns.scatterplot(x=\"X\", y=\"Y\",\n              data=tsne_df);","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}